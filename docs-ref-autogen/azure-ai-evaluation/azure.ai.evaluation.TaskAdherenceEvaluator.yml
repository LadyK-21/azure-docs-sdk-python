### YamlMime:PythonClass
uid: azure.ai.evaluation.TaskAdherenceEvaluator
name: TaskAdherenceEvaluator
fullName: azure.ai.evaluation.TaskAdherenceEvaluator
module: azure.ai.evaluation
summary: "> [!NOTE]\n> This is an experimental class, and may change at any time.\
  \ Please see [https://aka.ms/azuremlexperimental](https://aka.ms/azuremlexperimental)\
  \ for more information.\n>\n\nThe Task Adherence evaluator assesses how well an\
  \ AI-generated response follows the assigned task based on:\n\n   * Alignment with\
  \ instructions and definitions \n\n   * Accuracy and clarity of the response \n\n\
  \   * Proper use of provided tool definitions \n\nScoring is based on five levels:\n\
  1. Fully Inadherent - Response completely ignores instructions.\n2. Barely Adherent\
  \ - Partial alignment with critical gaps.\n3. Moderately Adherent - Meets core requirements\
  \ but lacks precision.\n4. Mostly Adherent - Clear and accurate with minor issues.\n\
  5. Fully Adherent - Flawless adherence to instructions.\n\nThe evaluation includes\
  \ a step-by-step reasoning process, a brief explanation, and a final integer score."
constructor:
  syntax: TaskAdherenceEvaluator(model_config, *, threshold=3, **kwargs)
  parameters:
  - name: model_config
    description: Configuration for the Azure OpenAI model.
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:azure.ai.evaluation.AzureOpenAIModelConfiguration>,
      <xref:azure.ai.evaluation.OpenAIModelConfiguration>]
  keywordOnlyParameters:
  - name: threshold
    defaultValue: '3'
attributes:
- uid: azure.ai.evaluation.TaskAdherenceEvaluator.id
  name: id
  summary: Evaluator identifier, experimental and to be used only with evaluation
    in cloud.
  signature: id = None
