### YamlMime:PythonPackage
uid: azure.ai.projects
name: projects
fullName: azure.ai.projects
type: rootImport
functions:
- uid: azure.ai.projects.enable_telemetry
  name: enable_telemetry
  summary: "Enables telemetry collection with OpenTelemetry for Azure AI clients and\
    \ popular GenAI libraries.\n\nFollowing instrumentations are enabled (when corresponding\
    \ packages are installed):\n\n* Azure AI Agents (*azure-ai-agents*) \n\n* Azure\
    \ AI Inference (*azure-ai-inference*) \n\n* OpenAI (*opentelemetry-instrumentation-openai-v2*)\
    \ \n\n* Langchain (*opentelemetry-instrumentation-langchain*) \n\nThe recording\
    \ of prompt and completion messages is disabled by default. To enable it, set\
    \ the\n*AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED* environment variable to\
    \ *true*.\n\nWhen destination is provided, the method configures OpenTelemetry\
    \ SDK to export traces to\nstdout or OTLP (OpenTelemetry protocol) gRPC endpoint.\
    \ It's recommended for local\ndevelopment only. For production use, make sure\
    \ to configure OpenTelemetry SDK directly."
  signature: 'enable_telemetry(*, destination: TextIO | str | None = None, **kwargs)
    -> None'
  keywordOnlyParameters:
  - name: destination
    description: 'Recommended for local testing only. Set it to *sys.stdout* for

      tracing to console output, or a string holding the OpenTelemetry protocol (OTLP)

      endpoint such as "[http://localhost:4317](http://localhost:4317).

      If not provided, the method enables instrumentations, but does not configure
      OpenTelemetry

      SDK to export traces.'
    defaultValue: None
    types:
    - <xref:typing.Union>[<xref:typing.TextIO>, <xref:str>, <xref:None>]
classes:
- azure.ai.projects.AIProjectClient
- azure.ai.projects.PromptTemplate
packages:
- azure.ai.projects.aio
- azure.ai.projects.models
- azure.ai.projects.operations
